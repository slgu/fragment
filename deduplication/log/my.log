2015-09-29 16:28:59,920 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:28:59,928 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:28:59,928 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:28:59,929 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:28:59,975 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:28:59,976 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:28:59,979 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:28:59,980 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:28:59,982 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:00,036 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:00,092 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:00,093 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:00,095 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:00,096 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:09,646 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:09,654 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:09,654 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:09,655 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:09,700 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:09,702 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:09,707 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:09,708 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:09,709 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:09,774 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:09,831 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:09,831 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:09,834 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:09,835 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:09,947 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:09,969 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:09,981 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,213 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:10,225 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:29:10,226 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:29:10,304 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.mkdir(HdfsDao.java:38)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:10,305 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:29:10,601 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:29:27,017 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:27,026 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:27,026 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:27,027 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:27,071 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:27,073 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:27,076 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:27,077 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:27,078 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:27,128 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:27,185 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:27,186 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:27,188 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:27,189 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:27,295 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:27,309 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:27,320 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,564 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:29:39,891 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:39,899 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:39,899 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:39,900 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:39,946 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:39,948 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:39,950 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:39,951 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:39,952 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:40,005 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:40,066 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:40,067 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:40,069 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:40,070 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:40,179 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:40,196 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:40,208 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,428 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:40,439 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:29:40,440 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:29:40,464 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.mkdir(HdfsDao.java:38)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:40,465 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:33:10,077 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:33:10,085 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:33:10,085 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:33:10,086 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:33:10,129 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:33:10,131 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:33:10,134 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:33:10,135 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:33:10,189 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:33:10,241 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:33:10,241 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:33:10,244 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:33:10,245 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:33:10,344 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:33:10,359 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:33:10,371 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,578 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:33:10,589 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:33:10,590 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:33:10,614 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:28)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:33:10,615 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
