2015-09-29 16:28:59,920 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:28:59,928 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:28:59,928 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:28:59,929 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:28:59,975 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:28:59,976 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:28:59,979 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:28:59,980 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:28:59,980 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:28:59,982 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:00,036 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:00,088 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:00,092 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:00,093 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:00,095 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:00,096 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:09,646 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:09,654 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:09,654 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:09,655 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:09,700 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:09,702 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:09,707 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:09,708 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:09,708 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:09,709 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:09,774 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:09,826 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:09,831 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:09,831 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:09,834 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:09,835 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:09,917 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:09,947 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:09,969 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:09,981 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,213 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:10,225 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:29:10,226 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:29:10,304 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.mkdir(HdfsDao.java:38)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:10,305 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:29:10,601 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:10,602 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:29:27,017 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:27,026 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:27,026 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:27,027 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:27,071 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:27,073 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:27,076 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:27,077 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:27,077 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:27,078 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:27,128 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:27,181 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:27,185 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:27,186 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:27,188 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:27,189 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:27,266 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:27,295 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:27,309 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:27,320 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,564 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:27,569 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:29:39,891 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:39,899 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:29:39,899 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:29:39,900 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:29:39,946 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:29:39,948 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:29:39,950 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:29:39,951 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:29:39,951 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:29:39,952 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:29:40,005 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:29:40,062 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:29:40,066 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:29:40,067 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:29:40,069 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:29:40,070 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:29:40,154 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:29:40,179 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:29:40,196 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:29:40,208 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,428 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:29:40,439 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:29:40,440 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:29:40,464 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.mkdir(HdfsDao.java:38)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:29:40,465 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:29:40,472 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 16:33:10,077 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:33:10,085 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2015-09-29 16:33:10,085 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2015-09-29 16:33:10,086 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 16:33:10,129 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 16:33:10,131 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/Users/slgu1/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
2015-09-29 16:33:10,134 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 16:33:10,134 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 16:33:10,135 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 16:33:10,189 [main] DEBUG org.apache.hadoop.util.Shell -  Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:749)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:734)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:607)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2748)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2740)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2606)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:27)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.util.Shell -  setsid is not available on this machine. So not using it.
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 16:33:10,236 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 16:33:10,241 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 16:33:10,241 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 16:33:10,244 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: slgu1
2015-09-29 16:33:10,245 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:slgu1 (auth:SIMPLE)
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 16:33:10,319 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 16:33:10,344 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 16:33:10,359 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5123a213
2015-09-29 16:33:10,371 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,578 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 16:33:10,589 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 16:33:10,590 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 16:33:10,614 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to 10.211.55.3/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:28)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 16:33:10,615 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1018298342) connection to /10.211.55.3:9000 from slgu1: closed
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@69379752
2015-09-29 16:33:10,927 [Thread-1] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:52:23,922 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:23,957 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:23,957 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:23,959 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:52:24,350 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:52:24,360 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:52:24,378 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:52:24,378 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:52:24,378 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:52:24,378 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:52:24,378 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:52:24,378 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:52:24,788 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:52:24,789 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:52:24,791 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:52:24,791 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:52:24,794 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:52:24,794 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:52:24,896 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:52:24,896 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:52:24,896 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:52:24,896 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:52:24,942 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:52:24,984 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@16db2cce
2015-09-29 13:52:24,987 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:25,236 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:52:25,248 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:52:25,249 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:52:25,491 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:28)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:56)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 13:52:25,494 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (430016376) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:52:25,499 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:25,499 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:25,499 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:25,499 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:52:57,851 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:57,859 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:57,859 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:52:57,860 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:52:58,040 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:52:58,042 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:52:58,052 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:52:58,052 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:52:58,052 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:52:58,052 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:52:58,052 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:52:58,053 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:52:58,406 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:52:58,407 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:52:58,409 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:52:58,409 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:52:58,411 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:52:58,412 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:52:58,539 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:52:58,539 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:52:58,539 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:52:58,539 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:52:58,606 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:52:58,648 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@16db2cce
2015-09-29 13:52:58,652 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:59,021 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:52:59,034 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:52:59,035 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:52:59,152 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:29)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:21)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:57)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 13:52:59,155 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1002759277) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:52:59,161 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:59,161 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:59,161 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@41de3998
2015-09-29 13:52:59,161 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:54:45,165 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:54:45,181 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:54:45,182 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:54:45,183 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:54:45,477 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:54:45,481 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:54:45,482 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:54:45,482 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:54:45,482 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:54:45,482 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:54:45,482 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:54:45,485 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:54:45,517 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:54:45,517 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:54:45,519 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:54:45,519 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:54:45,521 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:54:45,522 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:54:45,711 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:54:45,717 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:54:45,717 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:54:45,717 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:54:45,765 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:54:45,804 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5af8f1d7
2015-09-29 13:54:45,812 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@457b9183
2015-09-29 13:54:46,065 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:54:46,077 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:54:46,077 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:54:46,320 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:35)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:22)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 13:54:46,322 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1060470494) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:54:46,332 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@457b9183
2015-09-29 13:54:46,332 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@457b9183
2015-09-29 13:54:46,332 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@457b9183
2015-09-29 13:54:46,332 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:55:13,552 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:13,568 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:13,568 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:13,569 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:55:13,707 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:55:13,709 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:55:13,712 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:55:13,713 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:55:13,713 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:55:13,713 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:55:13,718 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:55:13,719 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:55:13,749 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:55:13,749 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:55:13,751 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:55:13,751 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:55:13,754 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:55:13,754 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:55:13,900 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:55:13,900 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:55:13,900 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:55:13,900 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:55:13,923 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:55:13,949 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@d8ae503
2015-09-29 13:55:13,953 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@2cbdbe98
2015-09-29 13:55:14,246 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:55:14,258 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:55:14,259 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:55:14,304 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:35)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:22)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:63)
2015-09-29 13:55:14,306 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (108940648) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:55:14,312 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@2cbdbe98
2015-09-29 13:55:14,312 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@2cbdbe98
2015-09-29 13:55:14,312 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@2cbdbe98
2015-09-29 13:55:14,312 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:55:16,318 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:16,335 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:16,336 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:55:16,337 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:55:16,687 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:55:16,690 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:55:16,694 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:55:16,694 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:55:16,694 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:55:16,694 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:55:16,694 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:55:16,695 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:55:16,710 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:55:16,710 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:55:16,712 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:55:16,712 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:55:16,714 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:55:16,716 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:55:16,819 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:55:16,819 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:55:16,819 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:55:16,819 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:55:16,845 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:55:16,862 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@dcd88ea
2015-09-29 13:55:16,865 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:55:17,273 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:55:17,284 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:55:17,285 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:55:17,325 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:35)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:22)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 13:55:17,327 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:55:17,333 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:55:17,333 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:55:17,333 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:55:17,333 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:56:13,733 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:13,763 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:13,766 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:13,771 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:56:14,244 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:56:14,249 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:56:14,252 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:56:14,253 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:56:14,253 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:56:14,253 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:56:14,253 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:56:14,258 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:56:14,315 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:56:14,315 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:56:14,319 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:56:14,319 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:56:14,322 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:56:14,323 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:56:14,593 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:56:14,596 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:56:14,596 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:56:14,596 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:56:14,763 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:56:14,838 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@50a14c18
2015-09-29 13:56:14,861 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@74b93ab6
2015-09-29 13:56:15,268 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:15,313 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:15,313 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:15,320 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:56:15,761 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:56:15,762 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:56:15,763 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:56:15,764 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:56:15,764 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:56:15,764 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:56:15,764 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:56:15,764 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:56:15,794 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:56:15,794 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:56:15,798 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:56:15,798 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:56:15,800 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:56:15,801 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:56:15,856 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:56:15,884 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:56:15,885 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to locahost/198.105.244.228:9000
2015-09-29 13:56:15,979 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:56:15,979 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:56:15,979 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:56:15,979 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:56:16,197 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:56:16,218 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@dcd88ea
2015-09-29 13:56:16,222 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:56:16,455 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:56:16,466 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:56:16,467 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to locahost/198.105.244.228:9000
2015-09-29 13:56:27,100 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:56:27,101 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:56:27,101 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:56:27,101 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:56:29,068 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@74b93ab6
2015-09-29 13:56:29,068 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@74b93ab6
2015-09-29 13:56:29,068 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@74b93ab6
2015-09-29 13:56:29,068 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:56:36,495 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 0 time(s); maxRetries=45
2015-09-29 13:56:40,809 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
2015-09-29 13:56:40,830 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
2015-09-29 13:56:40,830 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, value=[GetGroups], valueName=Time, always=false, type=DEFAULT, sampleName=Ops)
2015-09-29 13:56:40,831 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:56:41,010 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:56:41,013 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:56:41,019 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:56:41,019 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:56:41,020 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:56:41,020 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:56:41,020 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:56:41,020 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:56:41,052 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:56:41,053 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:56:41,055 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:56:41,055 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:56:41,057 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:56:41,058 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:56:41,183 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:56:41,184 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:56:41,184 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:56:41,184 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:56:41,309 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:56:41,331 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@24efb363
2015-09-29 13:56:41,335 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:56:41,564 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:56:41,576 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:56:41,576 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to locahost/198.105.244.228:9000
2015-09-29 13:56:45,439 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:56:45,439 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:56:45,439 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:56:45,440 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:56:56,586 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 1 time(s); maxRetries=45
2015-09-29 13:56:59,267 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:59,283 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:59,283 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:56:59,287 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:56:59,614 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:56:59,616 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:56:59,618 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:56:59,618 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:56:59,618 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:56:59,618 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:56:59,618 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:56:59,619 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:56:59,635 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:56:59,635 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:56:59,638 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:56:59,638 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:56:59,641 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:56:59,643 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:56:59,773 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:56:59,773 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:56:59,773 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:56:59,773 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:56:59,809 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:56:59,855 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@dcd88ea
2015-09-29 13:56:59,863 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:57:00,102 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:57:00,113 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:57:00,113 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to localhost/127.0.0.1:9000
2015-09-29 13:57:00,125 [IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop: starting, having connections 1
2015-09-29 13:57:00,127 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop sending #0
2015-09-29 13:57:00,133 [IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop got value #0
2015-09-29 13:57:00,133 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine -  Call: getFileInfo took 28ms
2015-09-29 13:57:00,167 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:57:00,167 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:57:00,167 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@338e5318
2015-09-29 13:57:00,167 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:57:00,167 [IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop: closed
2015-09-29 13:57:00,167 [IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1360806205) connection to localhost/127.0.0.1:9000 from hadoop: stopped, remaining connections 0
2015-09-29 13:57:01,603 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 0 time(s); maxRetries=45
2015-09-29 13:57:07,333 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:07,343 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:07,344 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:07,345 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:57:07,624 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:57:07,625 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:57:07,626 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:57:07,626 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:57:07,626 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:57:07,626 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:57:07,626 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:57:07,627 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:57:07,665 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:57:07,666 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:57:07,668 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:57:07,668 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:57:07,670 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:57:07,671 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:57:07,864 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:57:07,864 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:57:07,864 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:57:07,864 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:57:07,933 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:57:07,997 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@24efb363
2015-09-29 13:57:08,010 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:08,242 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:57:08,257 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:57:08,258 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to localhost/127.0.0.1:9000
2015-09-29 13:57:08,276 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: starting, having connections 1
2015-09-29 13:57:08,276 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop sending #0
2015-09-29 13:57:08,282 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop got value #0
2015-09-29 13:57:08,282 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine -  Call: getFileInfo took 36ms
2015-09-29 13:57:08,310 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:08,310 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:08,310 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:08,310 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:57:08,310 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: closed
2015-09-29 13:57:08,310 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: stopped, remaining connections 0
2015-09-29 13:57:13,727 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:13,735 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:13,736 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:13,737 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:57:14,111 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:57:14,115 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:57:14,116 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:57:14,117 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:57:14,117 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:57:14,117 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:57:14,117 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:57:14,118 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:57:14,169 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:57:14,169 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:57:14,171 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:57:14,172 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:57:14,174 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:57:14,175 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:57:14,417 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:57:14,417 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:57:14,417 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:57:14,417 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:57:14,478 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:57:14,517 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@24efb363
2015-09-29 13:57:14,537 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:14,772 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:57:14,783 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:57:14,784 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to localhost/127.0.0.1:9000
2015-09-29 13:57:14,801 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: starting, having connections 1
2015-09-29 13:57:14,803 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop sending #0
2015-09-29 13:57:14,809 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop got value #0
2015-09-29 13:57:14,809 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine -  Call: getFileInfo took 34ms
2015-09-29 13:57:14,830 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop sending #1
2015-09-29 13:57:14,832 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop got value #1
2015-09-29 13:57:14,832 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine -  Call: getFileInfo took 2ms
2015-09-29 13:57:14,832 [main] DEBUG org.apache.hadoop.hdfs.DFSClient -  /input/hello: masked=rwxr-xr-x
2015-09-29 13:57:14,834 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop sending #2
2015-09-29 13:57:14,836 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop got value #2
2015-09-29 13:57:14,836 [main] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine -  Call: mkdirs took 2ms
2015-09-29 13:57:14,842 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:14,842 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:14,842 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@44a7bdab
2015-09-29 13:57:14,842 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:57:14,843 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: closed
2015-09-29 13:57:14,843 [IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (638223659) connection to localhost/127.0.0.1:9000 from hadoop: stopped, remaining connections 0
2015-09-29 13:57:16,607 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 2 time(s); maxRetries=45
2015-09-29 13:57:21,760 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 1 time(s); maxRetries=45
2015-09-29 13:57:36,782 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 3 time(s); maxRetries=45
2015-09-29 13:57:38,344 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:38,370 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:38,370 [main] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory -  field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
2015-09-29 13:57:38,372 [main] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl -  UgiMetrics, User and group related metrics
2015-09-29 13:57:38,734 [main] DEBUG org.apache.hadoop.security.authentication.util.KerberosName -  Kerberos krb5 configuration not found, setting default realm to empty
2015-09-29 13:57:38,737 [main] DEBUG org.apache.hadoop.security.Groups -   Creating new Groups object
2015-09-29 13:57:38,738 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Trying to load the custom-built native-hadoop library...
2015-09-29 13:57:38,738 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-29 13:57:38,738 [main] DEBUG org.apache.hadoop.util.NativeCodeLoader -  java.library.path=/usr/local/idea/bin::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2015-09-29 13:57:38,738 [main] WARN  org.apache.hadoop.util.NativeCodeLoader -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-29 13:57:38,738 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Falling back to shell based
2015-09-29 13:57:38,739 [main] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback -  Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-29 13:57:38,755 [main] DEBUG org.apache.hadoop.util.Shell -  setsid exited with exit code 0
2015-09-29 13:57:38,755 [main] DEBUG org.apache.hadoop.security.Groups -  Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2015-09-29 13:57:38,758 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login
2015-09-29 13:57:38,758 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  hadoop login commit
2015-09-29 13:57:38,760 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  using local user:UnixPrincipal: hadoop
2015-09-29 13:57:38,761 [main] DEBUG org.apache.hadoop.security.UserGroupInformation -  UGI loginUser:hadoop (auth:SIMPLE)
2015-09-29 13:57:38,966 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.use.legacy.blockreader.local = false
2015-09-29 13:57:38,966 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.read.shortcircuit = false
2015-09-29 13:57:38,966 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.client.domain.socket.data.traffic = false
2015-09-29 13:57:38,967 [main] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal -  dfs.domain.socket.path = 
2015-09-29 13:57:39,030 [main] DEBUG org.apache.hadoop.io.retry.RetryUtils -  multipleLinearRandomRetry = null
2015-09-29 13:57:39,108 [main] DEBUG org.apache.hadoop.ipc.Server -  rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@53635a08
2015-09-29 13:57:39,115 [main] DEBUG org.apache.hadoop.ipc.Client -  getting client out of cache: org.apache.hadoop.ipc.Client@4ebbfcba
2015-09-29 13:57:39,363 [main] DEBUG org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory -  Both short-circuit local reads and UNIX domain socket are disabled.
2015-09-29 13:57:39,374 [main] DEBUG org.apache.hadoop.ipc.Client -  The ping interval is 60000 ms.
2015-09-29 13:57:39,374 [main] DEBUG org.apache.hadoop.ipc.Client -  Connecting to /10.211.55.3:9000
2015-09-29 13:57:39,628 [main] DEBUG org.apache.hadoop.ipc.Client -  closing ipc connection to ubuntu.local/10.211.55.3:9000: Connection refused
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:740)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:707)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1785)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1068)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1064)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1398)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:35)
	at org.slgu.hdfs.HdfsDao.<init>(HdfsDao.java:22)
	at org.slgu.hdfs.HdfsDao.main(HdfsDao.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)
2015-09-29 13:57:39,631 [main] DEBUG org.apache.hadoop.ipc.Client -  IPC Client (1054818236) connection to /10.211.55.3:9000 from hadoop: closed
2015-09-29 13:57:39,636 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping client from cache: org.apache.hadoop.ipc.Client@4ebbfcba
2015-09-29 13:57:39,636 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  removing client from cache: org.apache.hadoop.ipc.Client@4ebbfcba
2015-09-29 13:57:39,636 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4ebbfcba
2015-09-29 13:57:39,636 [Thread-2] DEBUG org.apache.hadoop.ipc.Client -  Stopping client
2015-09-29 13:57:41,780 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 2 time(s); maxRetries=45
2015-09-29 13:57:56,802 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 4 time(s); maxRetries=45
2015-09-29 13:58:01,948 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 3 time(s); maxRetries=45
2015-09-29 13:58:16,888 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 5 time(s); maxRetries=45
2015-09-29 13:58:21,968 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 4 time(s); maxRetries=45
2015-09-29 13:58:36,905 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 6 time(s); maxRetries=45
2015-09-29 13:58:42,122 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 5 time(s); maxRetries=45
2015-09-29 13:58:56,974 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 7 time(s); maxRetries=45
2015-09-29 13:59:02,131 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 6 time(s); maxRetries=45
2015-09-29 13:59:16,991 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 8 time(s); maxRetries=45
2015-09-29 13:59:22,208 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 7 time(s); maxRetries=45
2015-09-29 13:59:37,171 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 9 time(s); maxRetries=45
2015-09-29 13:59:42,228 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 8 time(s); maxRetries=45
2015-09-29 13:59:57,191 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 10 time(s); maxRetries=45
2015-09-29 14:00:02,287 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 9 time(s); maxRetries=45
2015-09-29 14:00:17,306 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 11 time(s); maxRetries=45
2015-09-29 14:00:22,301 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 10 time(s); maxRetries=45
2015-09-29 14:00:37,326 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 12 time(s); maxRetries=45
2015-09-29 14:00:42,391 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 11 time(s); maxRetries=45
2015-09-29 14:00:57,473 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 13 time(s); maxRetries=45
2015-09-29 14:01:02,402 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 12 time(s); maxRetries=45
2015-09-29 14:01:17,490 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 14 time(s); maxRetries=45
2015-09-29 14:01:22,484 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 13 time(s); maxRetries=45
2015-09-29 14:01:37,569 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 15 time(s); maxRetries=45
2015-09-29 14:01:42,500 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 14 time(s); maxRetries=45
2015-09-29 14:01:57,588 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 16 time(s); maxRetries=45
2015-09-29 14:02:02,583 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 15 time(s); maxRetries=45
2015-09-29 14:02:17,745 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 17 time(s); maxRetries=45
2015-09-29 14:02:22,600 [main] INFO  org.apache.hadoop.ipc.Client -  Retrying connect to server: locahost/198.105.244.228:9000. Already tried 16 time(s); maxRetries=45
